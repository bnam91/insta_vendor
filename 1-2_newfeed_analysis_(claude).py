"""
ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì…ë ¥ íŒŒì¼:
1. 1-1_newfeed_crawl_data.json
   - í¬ë¡¤ë§ëœ ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ì›ë³¸ ë°ì´í„°
   - í¬í•¨ ì •ë³´: ê²Œì‹œë¬¼ ID, ë³¸ë¬¸ ë‚´ìš©, ì‘ì„±ì¼, ì‘ì„±ì ì •ë³´ ë“±

2. 2-2_influencer_processing_data.json
   - ì¸í”Œë£¨ì–¸ì„œ ì •ë³´ ë°ì´í„°
   - í¬í•¨ ì •ë³´: ì¸í”Œë£¨ì–¸ì„œ ID, ê³µêµ¬ìœ ë¬´, ë¸Œëœë“œ/ìƒí’ˆ ì •ë³´ ë“±

3. brand_category.json
   - ë¸Œëœë“œ ì¹´í…Œê³ ë¦¬ ê´€ë¦¬ ë°ì´í„°
   - í¬í•¨ ì •ë³´: ë¸Œëœë“œëª…, ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì •ë³´, ë³„ì¹­(aliases), ë ˆë²¨, ìƒíƒœ

ì¶œë ¥/ì—…ë°ì´íŠ¸ íŒŒì¼:
1. 1-1_newfeed_crawl_data.json
   - ë¶„ì„ ê²°ê³¼ê°€ ì¶”ê°€ëœ í”¼ë“œ ë°ì´í„°
   - ì¶”ê°€ë˜ëŠ” ì •ë³´: ê³µêµ¬ ì—¬ë¶€, ìƒí’ˆëª…, ë¸Œëœë“œëª…, ê³µêµ¬ ì‹œì‘ì¼/ì¢…ë£Œì¼

2. 2-2_influencer_processing_data.json
   - ì—…ë°ì´íŠ¸ë˜ëŠ” ì¸í”Œë£¨ì–¸ì„œ ì •ë³´
   - ë³€ê²½ì‚¬í•­: ê³µêµ¬ìœ ë¬´ ìƒíƒœ, ìƒˆë¡œìš´ ë¸Œëœë“œ/ìƒí’ˆ ì •ë³´
   - ë¸Œëœë“œë³„ ìƒí’ˆ ì´ë ¥ ê´€ë¦¬ (20ì¼ ì´ë‚´ ì¤‘ë³µ ì²´í¬)

3. unregistered_influencers.log
   - ë¯¸ë“±ë¡ ì¸í”Œë£¨ì–¸ì„œ ì •ë³´ ê¸°ë¡
   - í¬í•¨ ì •ë³´: ë°œê²¬ ì‹œê°„, ì¸í”Œë£¨ì–¸ì„œëª…, ê²Œì‹œë¬¼ ë§í¬

4. influencer_update_errors.log
   - ë°ì´í„° ì²˜ë¦¬ ì¤‘ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ ë¡œê·¸
   - í¬í•¨ ì •ë³´: ì‹œê°„, ì¸í”Œë£¨ì–¸ì„œëª…, ì˜¤ë¥˜ ë‚´ìš©

ì‹¤í–‰ ê²°ê³¼:
1. ì½˜ì†” ì¶œë ¥
   - ì´ ë¶„ì„í•  ê²Œì‹œê¸€ ìˆ˜ í‘œì‹œ
   - ê° ê²Œì‹œë¬¼ ë¶„ì„ ì§„í–‰ ìƒí™© (ìˆœì°¨ì ìœ¼ë¡œ í‘œì‹œ)
   - ì¤‘ë³µ ìƒí’ˆ ë°œê²¬ ì‹œ ì•Œë¦¼
   - ì—ëŸ¬ ë°œìƒ ì‹œ í•´ë‹¹ ê²Œì‹œë¬¼ IDì™€ ì—ëŸ¬ ë‚´ìš©
   - ì „ì²´ ë¶„ì„ ì™„ë£Œ ë©”ì‹œì§€

2. JSON íŒŒì¼ ì—…ë°ì´íŠ¸
   ì˜ˆì‹œ) 1-1_newfeed_crawl_data.json:
   {
     "ì‘ì„±ì": "ì¸í”Œë£¨ì–¸ì„œëª…",
     "ë³¸ë¬¸": "ê²Œì‹œë¬¼ ë‚´ìš©",
     "ì‘ì„±ì‹œê°„": "2024-03-15T14:30:00",
     "ê³µêµ¬í”¼ë“œ": "ê³µêµ¬ì˜¤í”ˆ",
     "ê³µêµ¬ìƒí’ˆ": "ìƒí’ˆëª…",
     "ë¸Œëœë“œ": "ë¸Œëœë“œëª…",
     "ì˜¤í”ˆì˜ˆì •ì¼": "2024-03-15",
     "ê³µêµ¬ë§ˆê°ì¼": "2024-03-20"
   }

3. ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì—…ë°ì´íŠ¸
   ì˜ˆì‹œ) 2-2_influencer_processing_data.json:
   {
     "username": "ì¸í”Œë£¨ì–¸ì„œëª…",
     "ê³µêµ¬ìœ ë¬´": "Y",
     "ë¸Œëœë“œ": [
       {
         "name": "ë¸Œëœë“œëª…",
         "category": "ì¹´í…Œê³ ë¦¬",
         "products": [
           {
             "item": "ìƒí’ˆëª…",
             "type": "ê³µêµ¬ì˜¤í”ˆ",
             "mentioned_date": "2024-03-15T14:30:00",
             "expected_date": "2024-03-15",
             "end_date": "2024-03-20",
             "item_feed_link": "ê²Œì‹œë¬¼ë§í¬",
             "preserve": ""
           }
         ]
       }
     ]
   }

ê¸°ëŠ¥:
1. JSON íŒŒì¼ì—ì„œ ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ë°ì´í„°ë¥¼ ì½ì–´ì˜´
2. Claude AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ê²Œì‹œë¬¼ ë¶„ì„:
   - ê³µêµ¬ ê²Œì‹œë¬¼ ì—¬ë¶€ íŒë‹¨ (ê³µêµ¬ì˜ˆê³ /ê³µêµ¬ì˜¤í”ˆ/ê³µêµ¬ë¦¬ë§ˆì¸ë“œ/í™•ì¸í•„ìš”/N)
   - ìƒí’ˆëª…, ë¸Œëœë“œëª… ì¶”ì¶œ
   - ê³µêµ¬ ì‹œì‘ì¼/ì¢…ë£Œì¼ ì¶”ì¶œ
3. ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ìë™ ì—…ë°ì´íŠ¸
4. ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ìë™ ì—…ë°ì´íŠ¸
5. ë¸Œëœë“œ ì¹´í…Œê³ ë¦¬ ê´€ë¦¬ ë° ìë™ ë“±ë¡

ë°ì´í„° ì²˜ë¦¬ ê·œì¹™:
1. ê³µêµ¬ ë¶„ë¥˜:
   - ê³µêµ¬ì˜ˆê³ : í–¥í›„ ê³µêµ¬ ì˜ˆì • ê²Œì‹œë¬¼
   - ê³µêµ¬ì˜¤í”ˆ: í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ê³µêµ¬
   - ê³µêµ¬ë¦¬ë§ˆì¸ë“œ: ë§ˆê° ì„ë°• ê³µêµ¬
   - í™•ì¸í•„ìš”: ê³µêµ¬ ì—¬ë¶€ ë¶ˆëª…í™•
   - N: ê³µêµ¬ ì•„ë‹˜

2. ë‚ ì§œ ì²˜ë¦¬:
   - YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì €ì¥
   - 'ë‹¹ì¼' í‘œì‹œëŠ” ê²Œì‹œë¬¼ ì‘ì„±ì¼ë¡œ ë³€í™˜
   - ì—°ë„ ë¯¸ì§€ì •ì‹œ í˜„ì¬ ì—°ë„ ì‚¬ìš©

3. ë¸Œëœë“œ ì²˜ë¦¬:
   - brand_category.jsonì—ì„œ ë¸Œëœë“œ ì •ê·œí™”
   - ë¯¸ë“±ë¡ ë¸Œëœë“œ ìë™ ë“±ë¡ (status: 'ready')
   - ë³„ì¹­(aliases) ê´€ë¦¬ ì§€ì›

4. ìƒí’ˆ ì¤‘ë³µ ì²´í¬:
   - ë™ì¼ ìƒí’ˆ 20ì¼ ì´ë‚´ ì¤‘ë³µ ë“±ë¡ ë°©ì§€
   - ì¤‘ë³µ ë°œê²¬ ì‹œ ì½˜ì†”ì— ì•Œë¦¼

ì˜¤ë¥˜ ì²˜ë¦¬:
- ê°œë³„ ê²Œì‹œë¬¼ ì²˜ë¦¬ ì‹¤íŒ¨ì‹œ ë‹¤ìŒ ê²Œì‹œë¬¼ë¡œ ì§„í–‰
- ì˜¤ë¥˜ ìƒì„¸ ë‚´ìš© ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
- ë¯¸ë“±ë¡ ì¸í”Œë£¨ì–¸ì„œ ë³„ë„ ë¡œê·¸ ê´€ë¦¬

ì£¼ì˜ì‚¬í•­:
- API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´ í¬í•¨
- ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„°ëŠ” ê±´ë„ˆëœ€
- ë¸Œëœë“œëª… ëˆ„ë½ì‹œ 'í™•ì¸í•„ìš”'ë¡œ ì„¤ì •
"""


import anthropic
import time
import json
from datetime import datetime
import os
from dotenv import load_dotenv
from pymongo import MongoClient
from pymongo.server_api import ServerApi

def get_mongodb_connection():
    uri = "mongodb+srv://coq3820:JmbIOcaEOrvkpQo1@cluster0.qj1ty.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0"
    client = MongoClient(uri, server_api=ServerApi('1'))
    
    try:
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        client.admin.command('ping')
        print("MongoDB ì—°ê²° ì„±ê³µ!")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒ
        db = client['insta09_database']
        
        # ì»¬ë ‰ì…˜ ë§¤í•‘
        collections = {
            'feeds': db['01_test_newfeed_crawl_data'],
            'influencers': db['02_test_influencer_data'],
            'brands': db['08_test_brand_category_data']
        }
        
        return client, collections
    except Exception as e:
        print(f"MongoDB ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        raise

def update_influencer_data(item, collections):
    try:
        # ë¸Œëœë“œ ì¹´í…Œê³ ë¦¬ ë°ì´í„° ë¡œë“œ
        brands_collection = collections['brands']
        brand_category_data = brands_collection.find_one()
        
        # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì°¾ê¸°
        influencers_collection = collections['influencers']
        influencer = influencers_collection.find_one({'username': item['author']})
        
        # ë¸Œëœë“œëª… ì •ê·œí™” ë° ì¹´í…Œê³ ë¦¬ ì°¾ê¸° í•¨ìˆ˜
        def normalize_brand(brand_name):
            brand_info = brands_collection.find_one({
                '$or': [
                    {'name': brand_name},
                    {'aliases': brand_name}
                ]
            })
            
            if brand_info:
                return {
                    'name': brand_info['name'],
                    'category': brand_info['category']
                }
            
            # ë¸Œëœë“œê°€ ì—†ëŠ” ê²½ìš° ìƒˆë¡œ ì¶”ê°€
            if brand_name and brand_name != 'í™•ì¸í•„ìš”':
                new_brand = {
                    'name': brand_name,
                    'category': '',
                    'aliases': [],
                    'level': '',
                    'status': 'ready'
                }
                brands_collection.insert_one(new_brand)
                return {
                    'name': brand_name,
                    'category': ''
                }
            return {
                'name': brand_name,
                'category': ''
            }

        if not influencer:
            # ë¯¸ë“±ë¡ ì¸í”Œë£¨ì–¸ì„œ ë¡œê·¸ ê¸°ë¡
            log_message = f"[{item['cr_at']}] ë¯¸ë“±ë¡ ì¸í”Œë£¨ì–¸ì„œ ë°œê²¬: {item['author']} (ê²Œì‹œë¬¼ë§í¬: {item['post_url']})\n"
            with open('unregistered_influencers.log', 'a', encoding='utf-8') as log_file:
                log_file.write(log_message)
            print(f"ë¯¸ë“±ë¡ ì¸í”Œë£¨ì–¸ì„œ ë¡œê·¸ ê¸°ë¡: {item['author']}")
            return

        # ê³µêµ¬ìœ ë¬´ ì—…ë°ì´íŠ¸
        if influencer.get('09_is') != 'Y':
            influencers_collection.update_one(
                {'username': item['author']},
                {'$set': {'09_is': 'Y'}}
            )

        brands = item['09_brand'].split(', ')
        for brand in brands:
            brand_info = normalize_brand(brand)
            normalized_brand_name = brand_info['name']
            
            # ë¸Œëœë“œ ì •ë³´ ì—…ë°ì´íŠ¸
            brand_data = {
                'name': normalized_brand_name,
                'category': brand_info['category'],
                'products': [{
                    'item': item['09_item'],
                    'type': item['09_feed'],
                    'mentioned_date': item['cr_at'],
                    'expected_date': item['open_date'],
                    'end_date': item['end_date'],
                    'item_feed_link': item['post_url'],
                    'preserve': ''
                }]
            }

            # ì¤‘ë³µ ì²´í¬ ë° ì—…ë°ì´íŠ¸
            existing_brand = influencers_collection.find_one({
                'username': item['author'],
                'brand': {
                    '$elemMatch': {
                        'products': {
                            '$elemMatch': {
                                'mentioned_date': item['cr_at'],
                                'item_feed_link': item['post_url']
                            }
                        }
                    }
                }
            })

            if existing_brand:
                print(f"ë™ì¼ ê²Œì‹œê¸€ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {item['post_url']}")
                continue

            # ê¸°ì¡´ ë¸Œëœë“œ ê²€ìƒ‰
            existing_brand = influencers_collection.find_one({
                'username': item['author'],
                'brand.name': normalized_brand_name
            })

            if existing_brand:
                # ì¤‘ë³µ ì²´í¬ ë¡œì§ (20ì¼ ì´ë‚´)
                products = existing_brand['brand'][0]['products']
                product_exists = False
                
                for product in products:
                    existing_date = datetime.strptime(product['mentioned_date'].split('T')[0], '%Y-%m-%d')
                    new_date = datetime.strptime(item['cr_at'].split('T')[0], '%Y-%m-%d')
                    date_diff = abs((new_date - existing_date).days)
                    
                    if (product['item'] == item['09_item'] and date_diff <= 20):
                        product_exists = True
                        print(f"ì¤‘ë³µ ìƒí’ˆ ë°œê²¬: {item['09_item']} - ê¸°ì¡´:{existing_date.date()} ì‹ ê·œ:{new_date.date()} (ì°¨ì´: {date_diff}ì¼)")
                        break

                if not product_exists:
                    influencers_collection.update_one(
                        {'username': item['author'], 'brand.name': normalized_brand_name},
                        {'$push': {'brand.$.products': brand_data['products'][0]}}
                    )
            else:
                # ìƒˆ ë¸Œëœë“œ ì¶”ê°€
                influencers_collection.update_one(
                    {'username': item['author']},
                    {'$push': {'brand': brand_data}}
                )

        print(f"ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: {item['author']}")

    except Exception as e:
        error_message = f"[{item['cr_at']}] ì˜¤ë¥˜ ë°œìƒ - ì¸í”Œë£¨ì–¸ì„œ: {item['author']}, ì˜¤ë¥˜: {str(e)}\n"
        with open('influencer_update_errors.log', 'a', encoding='utf-8') as error_file:
            error_file.write(error_message)
        print(f"ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def analyze_instagram_feed():
    try:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
        load_dotenv()
        client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
        
        # MongoDB ì—°ê²°
        mongo_client, collections = get_mongodb_connection()
        feeds_collection = collections['feeds']
        
        # ì²˜ë¦¬ë˜ì§€ ì•Šì€ í”¼ë“œ ë°ì´í„° ì¡°íšŒ
        unprocessed_feeds = feeds_collection.find({
            '$or': [
                {'processed': False},
                {'processed': {'$exists': False}}
            ]
        })
        total_feeds = feeds_collection.count_documents({
            '$or': [
                {'processed': False},
                {'processed': {'$exists': False}}
            ]
        })
        
        print(f"ì´ {total_feeds}ê°œì˜ ê²Œì‹œê¸€ì„ ë¶„ì„í•©ë‹ˆë‹¤...")
        
        # ê° ê²Œì‹œê¸€ ë¶„ì„
        for i, item in enumerate(unprocessed_feeds, start=1):
            print(f"\n[{i}/{total_feeds}] {i}ë²ˆ ê²Œì‹œê¸€ ë¶„ì„ ì¤‘...")
            
            try:
                # ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„°ì¸ì§€ í™•ì¸ (09_feed í•„ë“œë¡œ í™•ì¸)
                if item.get('09_feed'):
                    print(f"{i}ë²ˆ ê²Œì‹œê¸€: ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„°ì…ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                    feeds_collection.update_one(
                        {'_id': item['_id']},
                        {'$set': {'processed': True}}
                    )
                    continue

                # ë³¸ë¬¸ ë‚´ìš© í™•ì¸
                content = item.get('content')
                if not content or not content.strip():
                    print(f"{i}ë²ˆ ê²Œì‹œê¸€: ë³¸ë¬¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    continue  # processedë¥¼ Trueë¡œ ì„¤ì •í•˜ì§€ ì•Šê³  ë‹¤ìŒ ê²Œì‹œë¬¼ë¡œ ë„˜ì–´ê°
                
                print(f"{i}ë²ˆ ê²Œì‹œê¸€: í´ë¡œë“œ ë¶„ì„ ìš”ì²­ ì¤‘...")
                message = client.messages.create(
                    model="claude-3-5-sonnet-latest",
                    # model="claude-3-5-haiku-latest",
                    max_tokens=500,
                    temperature=0.3,
                    system="""You are analyzing Instagram feed content. Extract information and respond in the following JSON format only:
                    {
                        "is_group_buy": "ê³µêµ¬ì˜ˆê³ "/"ê³µêµ¬ì˜¤í”ˆ"/"ê³µêµ¬ë¦¬ë§ˆì¸ë“œ"/"í™•ì¸í•„ìš”"/"N",
                        "product_name": "Include all main product categories in the title",
                        "brand_name": "brand name here",
                        "start_date": "MM-DD format only if year is not specified",
                        "end_date": "MM-DD format only if year is not specified"
                    }
                    
                    For group buy classification:
                    - "ê³µêµ¬ì˜ˆê³ ": Post announces future group buy with specific future date
                    - "ê³µêµ¬ì˜¤í”ˆ": Post announces group buy opening today or is currently open
                    - "ê³µêµ¬ë¦¬ë§ˆì¸ë“œ": Post reminds of ongoing group buy or last call
                    - "í™•ì¸í•„ìš”": Unclear whether it's a group buy or needs verification
                    - "N": Not a group buy post
                    
                    Important indicators:
                    - ê³µêµ¬ì˜ˆê³ : "ê³§ ì˜¤í”ˆ", "ì˜¤í”ˆ ì˜ˆì •", "Coming soon", "ì¤€ë¹„ì¤‘"
                    - ê³µêµ¬ì˜¤í”ˆ: "OPEN", "ì˜¤í”ˆ", "ğ‘¶ğ‘·ğ‘¬ğ‘µ", "open", "ì‹œì‘", "ì˜¤í”ˆí–ˆì–´ìš”"
                    - ê³µêµ¬ë¦¬ë§ˆì¸ë“œ: "ë§ˆê°ì„ë°•", "ì˜¤ëŠ˜ë§ˆê°", "ë§ˆì§€ë§‰", "ì¬ê³  ì–¼ë§ˆì—†ì–´ìš”"
                    
                    For dates:
                    - If year is not specified in the content, only extract MM-DD
                    - If post mentions "OPEN", "ì˜¤í”ˆ", "ğ‘¶ğ‘·ğ‘¬ğ‘µ", "open" without specific date, mark as "ë‹¹ì¼"
                    - For shipping dates (e.g., "2/7ì¼ë¶€í„° ìˆœì°¨ ë°œì†¡"), use post date as start_date
                    - Do not assume or add any year information
                    - Return empty string if no date is found
                    
                    Important indicators for group buy (ê³µêµ¬):
                    - Keywords like "OPEN", "ì˜¤í”ˆ", "ğ‘¶ğ‘·ğ‘¬ğ‘µ", "open"
                    - "í”„ë¡œí•„ ë§í¬ì—ì„œ êµ¬ë§¤"
                    - Detailed product information with pricing
                    - Limited time offer implications
                    - Comment inducement for purchase intention
                    - Specific purchase instructions or links
                    
                    Return "í™•ì¸í•„ìš”" when:
                    - Post contains some group buy indicators but lacks crucial information
                    - Unclear whether it's a product review or group buy
                    - Contains purchase-related keywords but no clear group buy format

                    For dates:
                    - If year is not specified in the content, only extract MM-DD
                    - If post mentions "OPEN" without specific date, mark as "ë‹¹ì¼"
                    - Do not assume or add any year information
                    - Return empty string if no date is found
                 
                    
                    Do not include any other text in your response.""",
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": content
                                }
                            ]
                        }
                    ]
                )
                
                response = message.content[0].text if isinstance(message.content, list) else message.content
                result = json.loads(response)
                
                # 'ë‹¹ì¼' ì²˜ë¦¬
                if result['start_date'] == 'ë‹¹ì¼':
                    date_parts = item['cr_at'].split('T')[0].split('-')
                    result['start_date'] = f"{date_parts[1]}-{date_parts[2]}"
                    
                if result['end_date'] == 'ë‹¹ì¼':
                    date_parts = item['cr_at'].split('T')[0].split('-')
                    result['end_date'] = f"{date_parts[1]}-{date_parts[2]}"

                # ë¸Œëœë“œëª…ì´ ë¹„ì–´ìˆê³  ìƒí’ˆëª…ì´ ìˆëŠ” ê²½ìš° 'í™•ì¸í•„ìš”'ë¡œ ì„¤ì •
                if not result['brand_name'] and result['product_name']:
                    result['brand_name'] = 'í™•ì¸í•„ìš”'

                # ë³€í™˜ëœ ê°’ìœ¼ë¡œ Claude ì‘ë‹µ ì¶œë ¥
                print(f"{i}ë²ˆ ê²Œì‹œê¸€: í´ë¡œë“œ ì‘ë‹µ ë‚´ìš©: {json.dumps(result, ensure_ascii=False, indent=4)}")
                
                # ë‚ ì§œ í˜•ì‹ ê²€ì¦ ë° ì •ë¦¬ í•¨ìˆ˜
                def validate_date(date_str, created_date=None):
                    if not date_str or date_str.strip() == '':
                        return ''
                    try:
                        if date_str == 'ë‹¹ì¼' and created_date:
                            # created_dateì—ì„œ ì›”-ì¼ë§Œ ì¶”ì¶œ (MM-DD í˜•ì‹)
                            date_parts = created_date.split('T')[0].split('-')
                            return f"{date_parts[1]}-{date_parts[2]}"
                        
                        # MM-DD í˜•ì‹ì„ ì²˜ë¦¬
                        date_str = date_str.replace('/', '-').replace('.', '-')
                        parts = date_str.split('-')
                        
                        if len(parts) == 2:
                            # created_dateì—ì„œ ì—°ë„ ì¶”ì¶œ
                            year = created_date.split('T')[0].split('-')[0] if created_date else "2024"
                            month = parts[0].zfill(2)
                            day = parts[1].zfill(2)
                            return f"{year}-{month}-{day}"
                        elif len(parts) == 3:
                            year = parts[0]
                            if len(year) == 2:
                                year = f"20{year}"
                            month = parts[1].zfill(2)
                            day = parts[2].zfill(2)
                            return f"{year}-{month}-{day}"
                        return ''
                    except:
                        return ''

                # ë‚ ì§œ ê²€ì¦ ë° ì²˜ë¦¬
                created_date = item.get('cr_at')
                
                update_data = {}
                
                if result['is_group_buy'] in ['ê³µêµ¬ì˜ˆê³ ', 'ê³µêµ¬ì˜¤í”ˆ', 'ê³µêµ¬ë¦¬ë§ˆì¸ë“œ']:
                    # ì‹œì‘ì¼ ì²˜ë¦¬ - ì´ì œ 'ë‹¹ì¼' ì²˜ë¦¬ëŠ” ìœ„ì—ì„œ ì™„ë£Œë¨
                    start_date = validate_date(str(result['start_date']), created_date)
                    end_date = validate_date(str(result['end_date']), created_date)
                    
                    update_data = {
                        '09_feed': result['is_group_buy'],
                        '09_item': str(result['product_name']),
                        '09_brand': str(result['brand_name']),
                        'open_date': start_date,
                        'end_date': end_date,
                        '09_item_category': '',
                        'processed': True
                    }
                    
                    # MongoDB ì—…ë°ì´íŠ¸
                    feeds_collection.update_one(
                        {'_id': item['_id']},
                        {'$set': update_data}
                    )
                    
                    # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ item ì—…ë°ì´íŠ¸
                    item.update(update_data)
                    update_influencer_data(item, collections)
                    
                else:
                    update_data = {
                        '09_feed': 'N' if result['is_group_buy'] == 'N' else 'í™•ì¸í•„ìš”',
                        '09_item': '',
                        '09_brand': '',
                        'open_date': '',
                        'end_date': '',
                        '09_item_category': '',
                        'processed': True
                    }
                    
                    feeds_collection.update_one(
                        {'_id': item['_id']},
                        {'$set': update_data}
                    )
                
                # ê° ê²Œì‹œê¸€ ë¶„ì„ ì™„ë£Œ í›„ 1ì´ˆ ëŒ€ê¸°
                print(f"{i}ë²ˆ ê²Œì‹œê¸€: ì²˜ë¦¬ ì™„ë£Œ")
                
            except Exception as e:
                print(f"{i}ë²ˆ ê²Œì‹œê¸€: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {str(e)}")
                continue
        
        print("\nëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        mongo_client.close()
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    analyze_instagram_feed()
