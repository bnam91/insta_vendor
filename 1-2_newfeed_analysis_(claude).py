"""
ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì…ë ¥ íŒŒì¼:
1. 1-1_newfeed_crawl_data.json
   - í¬ë¡¤ë§ëœ ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ì›ë³¸ ë°ì´í„°
   - í¬í•¨ ì •ë³´: ê²Œì‹œë¬¼ ID, ë³¸ë¬¸ ë‚´ìš©, ì‘ì„±ì¼, ì‘ì„±ì ì •ë³´ ë“±

2. 2-2_influencer_processing_data.json
   - ì¸í”Œë£¨ì–¸ì„œ ì •ë³´ ë°ì´í„°
   - í¬í•¨ ì •ë³´: ì¸í”Œë£¨ì–¸ì„œ ID, ê³µêµ¬ìœ ë¬´, ë¸Œëœë“œ/ìƒí’ˆ ì •ë³´ ë“±

3. brand_category.json
   - ë¸Œëœë“œ ì¹´í…Œê³ ë¦¬ ê´€ë¦¬ ë°ì´í„°
   - í¬í•¨ ì •ë³´: ë¸Œëœë“œëª…, ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì •ë³´, ë³„ì¹­(aliases), ë ˆë²¨, ìƒíƒœ

ì¶œë ¥/ì—…ë°ì´íŠ¸ íŒŒì¼:
1. 1-1_newfeed_crawl_data.json
   - ë¶„ì„ ê²°ê³¼ê°€ ì¶”ê°€ëœ í”¼ë“œ ë°ì´í„°
   - ì¶”ê°€ë˜ëŠ” ì •ë³´: ê³µêµ¬ ì—¬ë¶€, ìƒí’ˆëª…, ë¸Œëœë“œëª…, ê³µêµ¬ ì‹œì‘ì¼/ì¢…ë£Œì¼

2. 2-2_influencer_processing_data.json
   - ì—…ë°ì´íŠ¸ë˜ëŠ” ì¸í”Œë£¨ì–¸ì„œ ì •ë³´
   - ë³€ê²½ì‚¬í•­: ê³µêµ¬ìœ ë¬´ ìƒíƒœ, ìƒˆë¡œìš´ ë¸Œëœë“œ/ìƒí’ˆ ì •ë³´
   - ë¸Œëœë“œë³„ ìƒí’ˆ ì´ë ¥ ê´€ë¦¬ (20ì¼ ì´ë‚´ ì¤‘ë³µ ì²´í¬)

3. unregistered_influencers.log
   - ë¯¸ë“±ë¡ ì¸í”Œë£¨ì–¸ì„œ ì •ë³´ ê¸°ë¡
   - í¬í•¨ ì •ë³´: ë°œê²¬ ì‹œê°„, ì¸í”Œë£¨ì–¸ì„œëª…, ê²Œì‹œë¬¼ ë§í¬

4. influencer_update_errors.log
   - ë°ì´í„° ì²˜ë¦¬ ì¤‘ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ ë¡œê·¸
   - í¬í•¨ ì •ë³´: ì‹œê°„, ì¸í”Œë£¨ì–¸ì„œëª…, ì˜¤ë¥˜ ë‚´ìš©

ì‹¤í–‰ ê²°ê³¼:
1. ì½˜ì†” ì¶œë ¥
   - ì´ ë¶„ì„í•  ê²Œì‹œê¸€ ìˆ˜ í‘œì‹œ
   - ê° ê²Œì‹œë¬¼ ë¶„ì„ ì§„í–‰ ìƒí™© (ìˆœì°¨ì ìœ¼ë¡œ í‘œì‹œ)
   - ì¤‘ë³µ ìƒí’ˆ ë°œê²¬ ì‹œ ì•Œë¦¼
   - ì—ëŸ¬ ë°œìƒ ì‹œ í•´ë‹¹ ê²Œì‹œë¬¼ IDì™€ ì—ëŸ¬ ë‚´ìš©
   - ì „ì²´ ë¶„ì„ ì™„ë£Œ ë©”ì‹œì§€

2. JSON íŒŒì¼ ì—…ë°ì´íŠ¸
   ì˜ˆì‹œ) 1-1_newfeed_crawl_data.json:
   {
     "ì‘ì„±ì": "ì¸í”Œë£¨ì–¸ì„œëª…",
     "ë³¸ë¬¸": "ê²Œì‹œë¬¼ ë‚´ìš©",
     "ì‘ì„±ì‹œê°„": "2024-03-15T14:30:00",
     "ê³µêµ¬í”¼ë“œ": "ê³µêµ¬ì˜¤í”ˆ",
     "ê³µêµ¬ìƒí’ˆ": "ìƒí’ˆëª…",
     "ë¸Œëœë“œ": "ë¸Œëœë“œëª…",
     "ì˜¤í”ˆì˜ˆì •ì¼": "2024-03-15",
     "ê³µêµ¬ë§ˆê°ì¼": "2024-03-20"
   }

3. ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì—…ë°ì´íŠ¸
   ì˜ˆì‹œ) 2-2_influencer_processing_data.json:
   {
     "username": "ì¸í”Œë£¨ì–¸ì„œëª…",
     "ê³µêµ¬ìœ ë¬´": "Y",
     "ë¸Œëœë“œ": [
       {
         "name": "ë¸Œëœë“œëª…",
         "category": "ì¹´í…Œê³ ë¦¬",
         "products": [
           {
             "item": "ìƒí’ˆëª…",
             "type": "ê³µêµ¬ì˜¤í”ˆ",
             "mentioned_date": "2024-03-15T14:30:00",
             "expected_date": "2024-03-15",
             "end_date": "2024-03-20",
             "item_feed_link": "ê²Œì‹œë¬¼ë§í¬",
             "preserve": ""
           }
         ]
       }
     ]
   }

ê¸°ëŠ¥:
1. JSON íŒŒì¼ì—ì„œ ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ ë°ì´í„°ë¥¼ ì½ì–´ì˜´
2. Claude AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ê²Œì‹œë¬¼ ë¶„ì„:
   - ê³µêµ¬ ê²Œì‹œë¬¼ ì—¬ë¶€ íŒë‹¨ (ê³µêµ¬ì˜ˆê³ /ê³µêµ¬ì˜¤í”ˆ/ê³µêµ¬ë¦¬ë§ˆì¸ë“œ/í™•ì¸í•„ìš”/N)
   - ìƒí’ˆëª…, ë¸Œëœë“œëª… ì¶”ì¶œ
   - ê³µêµ¬ ì‹œì‘ì¼/ì¢…ë£Œì¼ ì¶”ì¶œ
3. ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ìë™ ì—…ë°ì´íŠ¸
4. ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ìë™ ì—…ë°ì´íŠ¸
5. ë¸Œëœë“œ ì¹´í…Œê³ ë¦¬ ê´€ë¦¬ ë° ìë™ ë“±ë¡

ë°ì´í„° ì²˜ë¦¬ ê·œì¹™:
1. ê³µêµ¬ ë¶„ë¥˜:
   - ê³µêµ¬ì˜ˆê³ : í–¥í›„ ê³µêµ¬ ì˜ˆì • ê²Œì‹œë¬¼
   - ê³µêµ¬ì˜¤í”ˆ: í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ê³µêµ¬
   - ê³µêµ¬ë¦¬ë§ˆì¸ë“œ: ë§ˆê° ì„ë°• ê³µêµ¬
   - í™•ì¸í•„ìš”: ê³µêµ¬ ì—¬ë¶€ ë¶ˆëª…í™•
   - N: ê³µêµ¬ ì•„ë‹˜

2. ë‚ ì§œ ì²˜ë¦¬:
   - YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì €ì¥
   - 'ë‹¹ì¼' í‘œì‹œëŠ” ê²Œì‹œë¬¼ ì‘ì„±ì¼ë¡œ ë³€í™˜
   - ì—°ë„ ë¯¸ì§€ì •ì‹œ í˜„ì¬ ì—°ë„ ì‚¬ìš©

3. ë¸Œëœë“œ ì²˜ë¦¬:
   - brand_category.jsonì—ì„œ ë¸Œëœë“œ ì •ê·œí™”
   - ë¯¸ë“±ë¡ ë¸Œëœë“œ ìë™ ë“±ë¡ (status: 'ready')
   - ë³„ì¹­(aliases) ê´€ë¦¬ ì§€ì›

4. ìƒí’ˆ ì¤‘ë³µ ì²´í¬:
   - ë™ì¼ ìƒí’ˆ 20ì¼ ì´ë‚´ ì¤‘ë³µ ë“±ë¡ ë°©ì§€
   - ì¤‘ë³µ ë°œê²¬ ì‹œ ì½˜ì†”ì— ì•Œë¦¼

ì˜¤ë¥˜ ì²˜ë¦¬:
- ê°œë³„ ê²Œì‹œë¬¼ ì²˜ë¦¬ ì‹¤íŒ¨ì‹œ ë‹¤ìŒ ê²Œì‹œë¬¼ë¡œ ì§„í–‰
- ì˜¤ë¥˜ ìƒì„¸ ë‚´ìš© ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
- ë¯¸ë“±ë¡ ì¸í”Œë£¨ì–¸ì„œ ë³„ë„ ë¡œê·¸ ê´€ë¦¬

ì£¼ì˜ì‚¬í•­:
- API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´ í¬í•¨
- ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„°ëŠ” ê±´ë„ˆëœ€
- ë¸Œëœë“œëª… ëˆ„ë½ì‹œ 'í™•ì¸í•„ìš”'ë¡œ ì„¤ì •
"""

#ì˜ˆì •
# ë¸Œëœë“œë”•ì…”ë„ˆë¦¬ ë§Œë“¤ì–´ì„œ ì…ë ¥ë˜ê²Œ
# ì•„ì´í…œ ì¹´í…Œê³ ë¦¬ ë§Œë“¤ì–´ì„œ ì…ë ¥ë˜ê²Œ

import anthropic
import time
import json
from datetime import datetime
import os
from dotenv import load_dotenv

def update_influencer_data(item):
    try:
        # ë¸Œëœë“œ ì¹´í…Œê³ ë¦¬ ë°ì´í„° ë¡œë“œ
        with open('brand_category.json', 'r', encoding='utf-8') as f:
            brand_category_data = json.load(f)

        with open('2-2_influencer_processing_data.json', 'r', encoding='utf-8') as file:
            influencer_data = json.load(file)
        
        # ë¸Œëœë“œëª… ì •ê·œí™” ë° ì¹´í…Œê³ ë¦¬ ì°¾ê¸° í•¨ìˆ˜
        def normalize_brand(brand_name):
            for main_brand, info in brand_category_data['brands'].items():
                if brand_name == main_brand or brand_name in info['aliases']:
                    return {
                        'name': main_brand,
                        'category': info['category']
                    }
            # ë¸Œëœë“œê°€ ì—†ëŠ” ê²½ìš° ìƒˆë¡œ ì¶”ê°€
            if brand_name and brand_name != 'í™•ì¸í•„ìš”':
                brand_category_data['brands'][brand_name] = {
                    'category': '',
                    'aliases': [],
                    'level': '',
                    'status': 'ready'
                }
                # brand_category.json íŒŒì¼ ì—…ë°ì´íŠ¸
                with open('brand_category.json', 'w', encoding='utf-8') as f:
                    json.dump(brand_category_data, f, ensure_ascii=False, indent=2)
                return {
                    'name': brand_name,
                    'category': ''
                }
            return {
                'name': brand_name,
                'category': ''
            }

        influencer_found = False
        for influencer in influencer_data:
            if influencer['username'] == item['ì‘ì„±ì']:
                influencer_found = True
                if influencer.get('ê³µêµ¬ìœ ë¬´') != 'Y':
                    influencer['ê³µêµ¬ìœ ë¬´'] = 'Y'
                
                brands = item['ë¸Œëœë“œ'].split(', ')
                
                for brand in brands:
                    # ë¸Œëœë“œëª… ì •ê·œí™” ë° ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
                    brand_info = normalize_brand(brand)
                    normalized_brand_name = brand_info['name']
                    
                    # 1-1 JSON íŒŒì¼ì˜ ë¸Œëœë“œëª…ë„ ì—…ë°ì´íŠ¸
                    item['ë¸Œëœë“œ'] = normalized_brand_name
                    
                    # ê¸°ì¡´ ë¸Œëœë“œ ì°¾ê¸°
                    brand_exists = False
                    for existing_brand in influencer['ë¸Œëœë“œ']:
                        if existing_brand['name'] == normalized_brand_name:
                            # ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸
                            existing_brand['category'] = brand_info['category']
                            
                            # ì¤‘ë³µ ì²´í¬
                            product_exists = False
                            for product in existing_brand['products']:
                                # ì‘ì„±ì‹œê°„ì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œí•˜ê³  datetime ê°ì²´ë¡œ ë³€í™˜
                                existing_date = datetime.strptime(product['mentioned_date'].split('T')[0], '%Y-%m-%d')
                                new_date = datetime.strptime(item['ì‘ì„±ì‹œê°„'].split('T')[0], '%Y-%m-%d')
                                
                                # ë‚ ì§œ ì°¨ì´ ê³„ì‚° (ì ˆëŒ€ê°’)
                                date_diff = abs((new_date - existing_date).days)
                                
                                if (product['item'] == item['ê³µêµ¬ìƒí’ˆ'] and 
                                    date_diff <= 20):  # 20ì¼ ì´ë‚´ë©´ ì¤‘ë³µìœ¼ë¡œ ì²˜ë¦¬
                                    product_exists = True
                                    print(f"ì¤‘ë³µ ìƒí’ˆ ë°œê²¬: {item['ê³µêµ¬ìƒí’ˆ']} - ê¸°ì¡´:{existing_date.date()} ì‹ ê·œ:{new_date.date()} (ì°¨ì´: {date_diff}ì¼)")
                                    break
                            
                            # ì¤‘ë³µì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶”ê°€
                            if not product_exists:
                                existing_brand['products'].append({
                                    'item': item['ê³µêµ¬ìƒí’ˆ'],
                                    'type': item['ê³µêµ¬í”¼ë“œ'],
                                    'mentioned_date': item['ì‘ì„±ì‹œê°„'],
                                    'expected_date': item['ì˜¤í”ˆì˜ˆì •ì¼'],
                                    'end_date': item['ê³µêµ¬ë§ˆê°ì¼'],
                                    'item_feed_link': item['ê²Œì‹œë¬¼ë§í¬'],
                                    'preserve': ''
                                })
                            brand_exists = True
                            break
                    
                    # ìƒˆë¡œìš´ ë¸Œëœë“œì¸ ê²½ìš°
                    if not brand_exists:
                        influencer['ë¸Œëœë“œ'].append({
                            'name': normalized_brand_name,
                            'category': brand_info['category'],
                            'products': [{
                                'item': item['ê³µêµ¬ìƒí’ˆ'],
                                'type': item['ê³µêµ¬í”¼ë“œ'],
                                'mentioned_date': item['ì‘ì„±ì‹œê°„'],
                                'expected_date': item['ì˜¤í”ˆì˜ˆì •ì¼'],
                                'end_date': item['ê³µêµ¬ë§ˆê°ì¼'],
                                'item_feed_link': item['ê²Œì‹œë¬¼ë§í¬'],
                                'preserve': ''
                            }]
                        })
                break
        
        # usernameì´ ì—†ëŠ” ê²½ìš° ë¡œê·¸ ê¸°ë¡
        if not influencer_found:
            log_message = f"[{item['ì‘ì„±ì‹œê°„']}] ë¯¸ë“±ë¡ ì¸í”Œë£¨ì–¸ì„œ ë°œê²¬: {item['ì‘ì„±ì']} (ê²Œì‹œë¬¼ë§í¬: {item['ê²Œì‹œë¬¼ë§í¬']})\n"
            with open('unregistered_influencers.log', 'a', encoding='utf-8') as log_file:
                log_file.write(log_message)
            print(f"ë¯¸ë“±ë¡ ì¸í”Œë£¨ì–¸ì„œ ë¡œê·¸ ê¸°ë¡: {item['ì‘ì„±ì']}")
            return
        
        # ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ì €ì¥
        with open('2-2_influencer_processing_data.json', 'w', encoding='utf-8') as file:
            json.dump(influencer_data, file, ensure_ascii=False, indent=2)
            
        print(f"ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: {item['ì‘ì„±ì']}")
        
    except Exception as e:
        error_message = f"[{item['ì‘ì„±ì‹œê°„']}] ì˜¤ë¥˜ ë°œìƒ - ì¸í”Œë£¨ì–¸ì„œ: {item['ì‘ì„±ì']}, ì˜¤ë¥˜: {str(e)}\n"
        with open('influencer_update_errors.log', 'a', encoding='utf-8') as error_file:
            error_file.write(error_message)
        print(f"ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def analyze_instagram_feed():
    try:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
        load_dotenv()  # .env íŒŒì¼ ë¡œë“œ
        client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
        
        # JSON íŒŒì¼ ì½ê¸°
        with open('1-1_newfeed_crawl_data.json', 'r', encoding='utf-8') as file:
            data = json.load(file)
        
        print(f"ì´ {len(data)}ê°œì˜ ê²Œì‹œê¸€ì„ ë¶„ì„í•©ë‹ˆë‹¤...")
        
        # ê° ê²Œì‹œê¸€ ë¶„ì„
        for i, item in enumerate(data, start=1):
            print(f"\n[{i}/{len(data)}] {i}ë²ˆ ê²Œì‹œê¸€ ë¶„ì„ ì¤‘...")
            
            try:
                # ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„°ì¸ì§€ í™•ì¸ (09_feed í•„ë“œë¡œ ë³€ê²½)
                if item.get('09_feed'):
                    print(f"{i}ë²ˆ ê²Œì‹œê¸€: ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„°ì…ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue
                
                # ë³¸ë¬¸ ë‚´ìš© í™•ì¸ (content í•„ë“œë¡œ ë³€ê²½)
                content = item.get('content')
                if not content or not content.strip():
                    print(f"{i}ë²ˆ ê²Œì‹œê¸€: ë³¸ë¬¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    continue
                
                print(f"{i}ë²ˆ ê²Œì‹œê¸€: í´ë¡œë“œ ë¶„ì„ ìš”ì²­ ì¤‘...")
                message = client.messages.create(
                    model="claude-3-5-sonnet-latest",
                    # model="claude-3-5-haiku-latest",
                    max_tokens=500,
                    temperature=0.3,
                    system="""You are analyzing Instagram feed content. Extract information and respond in the following JSON format only:
                    {
                        "is_group_buy": "ê³µêµ¬ì˜ˆê³ "/"ê³µêµ¬ì˜¤í”ˆ"/"ê³µêµ¬ë¦¬ë§ˆì¸ë“œ"/"í™•ì¸í•„ìš”"/"N",
                        "product_name": "Include all main product categories in the title",
                        "brand_name": "brand name here",
                        "start_date": "MM-DD format only if year is not specified",
                        "end_date": "MM-DD format only if year is not specified"
                    }
                    
                    For group buy classification:
                    - "ê³µêµ¬ì˜ˆê³ ": Post announces future group buy with specific future date
                    - "ê³µêµ¬ì˜¤í”ˆ": Post announces group buy opening today or is currently open
                    - "ê³µêµ¬ë¦¬ë§ˆì¸ë“œ": Post reminds of ongoing group buy or last call
                    - "í™•ì¸í•„ìš”": Unclear whether it's a group buy or needs verification
                    - "N": Not a group buy post
                    
                    Important indicators:
                    - ê³µêµ¬ì˜ˆê³ : "ê³§ ì˜¤í”ˆ", "ì˜¤í”ˆ ì˜ˆì •", "Coming soon", "ì¤€ë¹„ì¤‘"
                    - ê³µêµ¬ì˜¤í”ˆ: "OPEN", "ì˜¤í”ˆ", "ğ‘¶ğ‘·ğ‘¬ğ‘µ", "open", "ì‹œì‘", "ì˜¤í”ˆí–ˆì–´ìš”"
                    - ê³µêµ¬ë¦¬ë§ˆì¸ë“œ: "ë§ˆê°ì„ë°•", "ì˜¤ëŠ˜ë§ˆê°", "ë§ˆì§€ë§‰", "ì¬ê³  ì–¼ë§ˆì—†ì–´ìš”"
                    
                    For dates:
                    - If year is not specified in the content, only extract MM-DD
                    - If post mentions "OPEN", "ì˜¤í”ˆ", "ğ‘¶ğ‘·ğ‘¬ğ‘µ", "open" without specific date, mark as "ë‹¹ì¼"
                    - For shipping dates (e.g., "2/7ì¼ë¶€í„° ìˆœì°¨ ë°œì†¡"), use post date as start_date
                    - Do not assume or add any year information
                    - Return empty string if no date is found
                    
                    Important indicators for group buy (ê³µêµ¬):
                    - Keywords like "OPEN", "ì˜¤í”ˆ", "ğ‘¶ğ‘·ğ‘¬ğ‘µ", "open"
                    - "í”„ë¡œí•„ ë§í¬ì—ì„œ êµ¬ë§¤"
                    - Detailed product information with pricing
                    - Limited time offer implications
                    - Comment inducement for purchase intention
                    - Specific purchase instructions or links
                    
                    Return "í™•ì¸í•„ìš”" when:
                    - Post contains some group buy indicators but lacks crucial information
                    - Unclear whether it's a product review or group buy
                    - Contains purchase-related keywords but no clear group buy format

                    For dates:
                    - If year is not specified in the content, only extract MM-DD
                    - If post mentions "OPEN" without specific date, mark as "ë‹¹ì¼"
                    - Do not assume or add any year information
                    - Return empty string if no date is found
                 
                    
                    Do not include any other text in your response.""",
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": content
                                }
                            ]
                        }
                    ]
                )
                
                response = message.content[0].text if isinstance(message.content, list) else message.content
                result = json.loads(response)
                
                # 'ë‹¹ì¼' ì²˜ë¦¬
                if result['start_date'] == 'ë‹¹ì¼':
                    date_parts = item['ì‘ì„±ì‹œê°„'].split('T')[0].split('-')
                    result['start_date'] = f"{date_parts[1]}-{date_parts[2]}"
                    
                if result['end_date'] == 'ë‹¹ì¼':
                    date_parts = item['ì‘ì„±ì‹œê°„'].split('T')[0].split('-')
                    result['end_date'] = f"{date_parts[1]}-{date_parts[2]}"

                # ë¸Œëœë“œëª…ì´ ë¹„ì–´ìˆê³  ìƒí’ˆëª…ì´ ìˆëŠ” ê²½ìš° 'í™•ì¸í•„ìš”'ë¡œ ì„¤ì •
                if not result['brand_name'] and result['product_name']:
                    result['brand_name'] = 'í™•ì¸í•„ìš”'

                # ë³€í™˜ëœ ê°’ìœ¼ë¡œ Claude ì‘ë‹µ ì¶œë ¥
                print(f"{i}ë²ˆ ê²Œì‹œê¸€: í´ë¡œë“œ ì‘ë‹µ ë‚´ìš©: {json.dumps(result, ensure_ascii=False, indent=4)}")
                
                # ë‚ ì§œ í˜•ì‹ ê²€ì¦ ë° ì •ë¦¬ í•¨ìˆ˜
                def validate_date(date_str, created_date=None):
                    if not date_str or date_str.strip() == '':
                        return ''
                    try:
                        if date_str == 'ë‹¹ì¼' and created_date:
                            # created_dateì—ì„œ ì›”-ì¼ë§Œ ì¶”ì¶œ (MM-DD í˜•ì‹)
                            date_parts = created_date.split('T')[0].split('-')
                            return f"{date_parts[1]}-{date_parts[2]}"
                        
                        # MM-DD í˜•ì‹ì„ ì²˜ë¦¬
                        date_str = date_str.replace('/', '-').replace('.', '-')
                        parts = date_str.split('-')
                        
                        if len(parts) == 2:
                            # created_dateì—ì„œ ì—°ë„ ì¶”ì¶œ
                            year = created_date.split('T')[0].split('-')[0] if created_date else "2024"
                            month = parts[0].zfill(2)
                            day = parts[1].zfill(2)
                            return f"{year}-{month}-{day}"
                        elif len(parts) == 3:
                            year = parts[0]
                            if len(year) == 2:
                                year = f"20{year}"
                            month = parts[1].zfill(2)
                            day = parts[2].zfill(2)
                            return f"{year}-{month}-{day}"
                        return ''
                    except:
                        return ''

                # ë‚ ì§œ ê²€ì¦ ë° ì²˜ë¦¬
                created_date = item.get('cr_at')  # ì‘ì„±ì‹œê°„ í•„ë“œëª… ë³€ê²½
                
                if result['is_group_buy'] in ['ê³µêµ¬ì˜ˆê³ ', 'ê³µêµ¬ì˜¤í”ˆ', 'ê³µêµ¬ë¦¬ë§ˆì¸ë“œ']:
                    # ì‹œì‘ì¼ ì²˜ë¦¬ - ì´ì œ 'ë‹¹ì¼' ì²˜ë¦¬ëŠ” ìœ„ì—ì„œ ì™„ë£Œë¨
                    start_date = validate_date(str(result['start_date']), created_date)
                    end_date = validate_date(str(result['end_date']), created_date)
                    
                    # í•„ë“œëª… ë³€ê²½ì— ë”°ë¥¸ ë°ì´í„° ì—…ë°ì´íŠ¸
                    item.update({
                        '09_feed': result['is_group_buy'],  # ê³µêµ¬í”¼ë“œ -> 09_feed
                        '09_item': str(result['product_name']),  # ê³µêµ¬ìƒí’ˆ -> 09_item
                        '09_brand': str(result['brand_name']),  # ë¸Œëœë“œ -> 09_brand
                        'open_date': start_date,  # ì˜¤í”ˆì˜ˆì •ì¼ -> open_date
                        'end_date': end_date,  # ê³µêµ¬ë§ˆê°ì¼ -> end_date
                        '09_item_category': ''  # ìƒˆë¡œ ì¶”ê°€ëœ ì¹´í…Œê³ ë¦¬ í•„ë“œ
                    })
                    
                    # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ì—…ë°ì´íŠ¸ - item ì§ì ‘ ì „ë‹¬
                    update_influencer_data(item)
                    
                elif result['is_group_buy'] == 'í™•ì¸í•„ìš”':
                    item.update({
                        '09_feed': 'í™•ì¸í•„ìš”',
                        '09_item': '',
                        '09_brand': '',
                        'open_date': '',
                        'end_date': '',
                        '09_item_category': ''
                    })
                    
                else:
                    item.update({
                        '09_feed': 'N',
                        '09_item': '',
                        '09_brand': '',
                        'open_date': '',
                        'end_date': '',
                        '09_item_category': ''
                    })
                
                # JSON íŒŒì¼ ì €ì¥
                with open('1-1_newfeed_crawl_data.json', 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                
                print(f"{i}ë²ˆ ê²Œì‹œê¸€: ì²˜ë¦¬ ì™„ë£Œ")
                time.sleep(1)
                
            except Exception as e:
                print(f"{i}ë²ˆ ê²Œì‹œê¸€: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {str(e)}")
                continue
        
        print("\nëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    analyze_instagram_feed()
